# -*- coding: utf-8 -*-
"""Clothing recognition.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1lUrl-QYpfda7DY66ZsOHn-4ddh4jjKLn
"""

# https://pytorch.org/vision/stable/generated/torchvision.datasets.FashionMNIST.html#torchvision.datasets.FashionMNIST
from torchvision import datasets
from torchvision.transforms import ToTensor   # img -> tensor
import matplotlib.pyplot as plt
import random
from torch.utils.data import DataLoader  # batch


train_data = datasets.FashionMNIST(
    root="image",
    train=True,       # training set
    download=True,
    transform=ToTensor())   # image -> tensor

test_data = datasets.FashionMNIST(
    root="image",
    train=False,      # testing set
    download=True,
    transform=ToTensor())   # image -> tensor

# show images
random_idx = random.randint(0, len(train_data)-1)
img, label = train_data[random_idx]
class_names = train_data.classes
class_names[label]
plt.imshow(img.permute(1, 2, 0), cmap="gray")  # tensor[1, 28, 28] -> plt[28, 28, 1]
plt.title(class_names[label])

# When the amount of data is too large, classification is necessary.
# Because when there are a large number of samples, if the computer needs to process each sample individually before updating, the speed will be too slow.
len(train_data), len(test_data)

BATCH_SIZE = 32  # 32/64/128/256

train_dataloader = DataLoader(
    train_data,
    batch_size=BATCH_SIZE,
    shuffle=True)   # Shuffle the training set data.

test_dataloader = DataLoader(
    test_data,
    batch_size=BATCH_SIZE,
    shuffle=False)   # Shuffle the testing set data.

len(train_dataloader), len(test_dataloader)

# iterable = can inspect in a loop
#qq = [1, 2, 3]
#qq_iterator = iter(qq)
#next(qq_iterator) 1 -> 2 -> 3

x_first_batch, y_first_batch = next(iter(train_dataloader))

random_idx = random.randint(0, len(x_first_batch)-1)
img, label = x_first_batch[random_idx], y_first_batch[random_idx]

plt.imshow(img.permute(1, 2, 0))
plt.title(class_names[label])